{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Experiments - Multi-label MLP-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayn/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = [5, 10]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import hamming_loss, make_scorer, confusion_matrix\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from fastai import text as ft\n",
    "from fastai import dataloader as fd\n",
    "from fastai import dataset as fs\n",
    "from fastai import learner as fl\n",
    "from fastai import core as fc\n",
    "from fastai import metrics as fm\n",
    "\n",
    "\n",
    "from skai.runner import TextRunner, Adam_lambda\n",
    "from skai.mwrapper import MWrapper, SKModel\n",
    "from skai.utils import multi_to_text_out, multilabel_prediction, weights_init\n",
    "from skai.dataset import SimpleDataset, SimpleBoWDataset\n",
    "from skai.metrics import f1_micro_skai\n",
    "\n",
    "def mapt(f, *iters):\n",
    "    return tuple(map(f, *iters))\n",
    "\n",
    "def mapl(f, *iters):\n",
    "    return list(map(f, *iters))\n",
    "\n",
    "def manually_remove_problems(data):\n",
    "    \"\"\" remove problem from data if it has a certain tag\"\"\"\n",
    "    final_data = {}\n",
    "    remove = ['*special']\n",
    "    for i in data:\n",
    "        if set(data[i][1][0]).intersection(set(remove)) == set():\n",
    "            if data[i][0][0] != '':\n",
    "                final_data[i] = data[i]\n",
    "    return final_data\n",
    "\n",
    "def get_single_label_problems(data):\n",
    "    '''returns a dict of all problems which only have one label'''\n",
    "    single_label_problems = {}\n",
    "    for i in data:\n",
    "        if len(data[i][1][0]) == 1:\n",
    "            single_label_problems[i] = data[i]\n",
    "    return single_label_problems\n",
    "\n",
    "def get_classwise_distribution(data):\n",
    "    class_count = {}\n",
    "    for i in data:\n",
    "        for cls in data[i][1][0]:\n",
    "            if cls in class_count:\n",
    "                class_count[cls] +=1 \n",
    "            else:\n",
    "                class_count[cls] = 1\n",
    "    return class_count\n",
    "\n",
    "\n",
    "def get_topk_single_label_problems(data,k):\n",
    "    \"\"\" get top k by frequency single label problems\"\"\"\n",
    "    class_dict = get_classwise_distribution(data)\n",
    "    print(class_dict)\n",
    "    class_dict = dict(sorted(class_dict.items(), key=itemgetter(1), reverse=True)[:k])\n",
    "    print(set(class_dict.keys()))\n",
    "\n",
    "    topk_data = {}\n",
    "    for i in data:\n",
    "        if set(data[i][1][0]).intersection(set(class_dict.keys())) != set():\n",
    "            topk_data[i] = data[i]\n",
    "            \n",
    "    return topk_data\n",
    "\n",
    "def make_text_dataset(rdata):\n",
    "    Xtext, ytext = [], []\n",
    "    for url, data in rdata.items():\n",
    "        try:\n",
    "            ytext.append(data[1][0][0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        Xtext.append(data[0][0])\n",
    "    return Xtext, ytext\n",
    "\n",
    "def make_multi_text_dataset(rdata):\n",
    "    Xtext, ytext = [], []\n",
    "    for url, data in rdata.items():\n",
    "        try:\n",
    "            ytext.append(data[1][0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        Xtext.append(data[0][0])\n",
    "    return Xtext, ytext\n",
    "\n",
    "def get_class_list(labels):\n",
    "    return list(set(labels))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(22,16)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top10m = pickle.load(open('data/10multi_26aug.pkl', 'rb'))\n",
    "top20m = pickle.load(open('data/20multi_26aug.pkl', 'rb'))\n",
    "\n",
    "top10m, top20m = mapt(make_multi_text_dataset, [top10m, top20m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3737\n"
     ]
    }
   ],
   "source": [
    "print(len(top10m[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary search', 'data structures', 'brute force', 'dp']\n"
     ]
    }
   ],
   "source": [
    "print(top10m[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, class_num, hidden_size=200):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        out = torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: raw data cleaned.\n",
      "multilabel classification.\n"
     ]
    }
   ],
   "source": [
    "trunner = TextRunner([None], top10m[0], top10m[1], 'top10m')\n",
    "in_dim = len(trunner.alldata.tvectorizer.itos)\n",
    "Xall, yall = trunner.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13580\n"
     ]
    }
   ],
   "source": [
    "print(in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Fold.\n",
      "Note: Model directory for mlp_gpu0 exists.\n",
      "Note: Checkpoints directory for mlp_gpu0 exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c849201b9b4d9b825f7b761bde6302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai                \n",
      "    0      0.133656   0.123855   0.173739  \n",
      "    1      0.101464   0.123159   0.340613                     \n",
      "    2      0.068831   0.127369   0.367896                      \n",
      "    3      0.050323   0.141769   0.32142                       \n",
      "    4      0.042831   0.153103   0.358759                      \n",
      "    5      0.035586   0.149015   0.378039                      \n",
      "    6      0.027181   0.152278   0.362421                     \n",
      "    7      0.02152    0.164009   0.368968                      \n",
      "    8      0.016777   0.151592   0.327226                     \n",
      "    9      0.012315   0.147863   0.320118                     \n",
      "\n",
      "0.37928007023705007\n",
      "2-th Fold.\n",
      "Note: Model directory for mlp_gpu1 exists.\n",
      "Note: Checkpoints directory for mlp_gpu1 exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3969c1712a4896967d1bbfc5c80098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai               \n",
      "    0      0.132528   0.130356   0.140543  \n",
      "    1      0.100953   0.125768   0.297193                     \n",
      "    2      0.068866   0.129882   0.323839                     \n",
      "    3      0.048128   0.140387   0.317073                      \n",
      "    4      0.041373   0.159427   0.344739                     \n",
      "    5      0.034913   0.148388   0.380945                     \n",
      "    6      0.025803   0.166292   0.361987                     \n",
      "    7      0.019906   0.155543   0.361672                      \n",
      "    8      0.015195   0.162507   0.347014                      \n",
      "    9      0.011426   0.164993   0.314129                    \n",
      "\n",
      "0.38190517616354935\n",
      "3-th Fold.\n",
      "Note: Model directory for mlp_gpu2 exists.\n",
      "Note: Checkpoints directory for mlp_gpu2 exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1208ba32d519490780fde9290c2c2142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai                \n",
      "    0      0.132054   0.130825   0.130331  \n",
      "    1      0.10049    0.125557   0.296521                    \n",
      "    2      0.070161   0.130863   0.300328                      \n",
      "    3      0.049767   0.144435   0.300775                     \n",
      "    4      0.040082   0.143516   0.350424                     \n",
      "    5      0.030856   0.154066   0.33902                      \n",
      "    6      0.026763   0.15819    0.340212                      \n",
      "    7      0.02294    0.177889   0.345209                     \n",
      "    8      0.017784   0.16154    0.335007                     \n",
      "    9      0.012039   0.157985   0.289127                     \n",
      "\n",
      "0.3724504877327816\n",
      "4-th Fold.\n",
      "Note: Model directory for mlp_gpu3 exists.\n",
      "Note: Checkpoints directory for mlp_gpu3 exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bae7dca0484e1f8af1b67c955c74a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai               \n",
      "    0      0.134236   0.124963   0.195349  \n",
      "    1      0.103142   0.118612   0.34024                     \n",
      "    2      0.073069   0.12246    0.360292                      \n",
      "    3      0.054786   0.137721   0.369605                      \n",
      "    4      0.043833   0.141897   0.354921                      \n",
      "    5      0.0344     0.137382   0.392144                      \n",
      "    6      0.025027   0.135313   0.397811                      \n",
      "    7      0.019108   0.137577   0.410065                      \n",
      "    8      0.013238   0.147894   0.373691                     \n",
      "    9      0.010736   0.149705   0.368268                      \n",
      "\n",
      "0.38222222222222224\n",
      "5-th Fold.\n",
      "Note: Model directory for mlp_gpu4 exists.\n",
      "Note: Checkpoints directory for mlp_gpu4 exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dadbc09095e44a88fb218e4e6a69852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai               \n",
      "    0      0.131539   0.132491   0.138925  \n",
      "    1      0.101369   0.129498   0.295701                    \n",
      "    2      0.070883   0.133455   0.350476                      \n",
      "    3      0.050082   0.141444   0.376095                      \n",
      "    4      0.041048   0.146142   0.341252                     \n",
      "    5      0.032065   0.154627   0.343142                     \n",
      "    6      0.025099   0.169444   0.340833                      \n",
      "    7      0.021047   0.162055   0.312292                     \n",
      "    8      0.017266   0.158069   0.361169                     \n",
      "    9      0.01405    0.161161   0.327963                     \n",
      "\n",
      "0.38096922532720195\n",
      "6-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab33b627ba9f45cab14d36ca23127b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai               \n",
      "    0      0.133119   0.118955   0.191502  \n",
      "    1      0.100611   0.116793   0.332722                    \n",
      "    2      0.068995   0.121522   0.370443                     \n",
      "    3      0.049106   0.130021   0.379673                      \n",
      "    4      0.038991   0.157601   0.334649                     \n",
      "    5      0.033161   0.142031   0.363854                      \n",
      "    6      0.031781   0.140614   0.407898                     \n",
      "    7      0.023298   0.154061   0.369175                     \n",
      "    8      0.017123   0.146169   0.374326                     \n",
      "    9      0.013754   0.149588   0.381218                      \n",
      "\n",
      "0.38522660388463803\n",
      "7-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b259c1cfcb0a4bdca8001b0d6c300919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai                \n",
      "    0      0.135807   0.123702   0.171951  \n",
      "    1      0.104481   0.117317   0.32873                     \n",
      "    2      0.074178   0.124623   0.347045                     \n",
      "    3      0.055383   0.146495   0.3333                       \n",
      "    4      0.044061   0.130336   0.394129                      \n",
      "    5      0.030799   0.138042   0.344262                      \n",
      "    6      0.021097   0.145809   0.330482                     \n",
      "    7      0.016578   0.151428   0.392133                     \n",
      "    8      0.013762   0.15719    0.382694                      \n",
      "    9      0.014443   0.155172   0.348256                     \n",
      "\n",
      "0.3863434445995685\n",
      "8-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c1bd30d3e648778237a851cde204b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai                \n",
      "    0      0.133721   0.129273   0.182047  \n",
      "    1      0.10457    0.124549   0.331474                    \n",
      "    2      0.074789   0.127294   0.339184                     \n",
      "    3      0.050839   0.138336   0.341963                     \n",
      "    4      0.044106   0.141485   0.373623                     \n",
      "    5      0.034286   0.141971   0.410463                     \n",
      "    6      0.024203   0.15954    0.341025                     \n",
      "    7      0.018414   0.168159   0.360424                     \n",
      "    8      0.015421   0.160686   0.353421                     \n",
      "    9      0.012165   0.153621   0.350168                      \n",
      "\n",
      "0.3895560207116889\n",
      "9-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cbfb18fcbb43f5aaec838c82268cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai               \n",
      "    0      0.132076   0.126692   0.131628  \n",
      "    1      0.101647   0.123613   0.27347                      \n",
      "    2      0.069592   0.133422   0.335191                     \n",
      "    3      0.047905   0.148093   0.359538                     \n",
      "    4      0.038856   0.147122   0.411888                     \n",
      "    5      0.031889   0.146245   0.389301                     \n",
      "    6      0.023506   0.143046   0.383762                     \n",
      "    7      0.019451   0.145601   0.382234                     \n",
      "    8      0.01541    0.158734   0.334545                     \n",
      "    9      0.012068   0.158282   0.336603                      \n",
      "\n",
      "0.3925324047204488\n",
      "10-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8442758f6e534f839518c8cffa81893d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai               \n",
      "    0      0.134421   0.12965    0.071183  \n",
      "  0%|          | 0/106 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayn/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aayn/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1      0.103927   0.125368   0.279047                     \n",
      "    2      0.072042   0.132858   0.328218                      \n",
      "    3      0.051691   0.146659   0.30795                       \n",
      "    4      0.042555   0.156581   0.343581                      \n",
      "    5      0.035291   0.143799   0.342388                     \n",
      "    6      0.029574   0.1481     0.360839                     \n",
      "    7      0.026538   0.154848   0.3513                        \n",
      "    8      0.018324   0.161595   0.380917                     \n",
      "    9      0.013191   0.157548   0.319551                     \n",
      "\n",
      "0.39126289329981806\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "out_dim = 10\n",
    "\n",
    "all_preds, all_targs = [], []\n",
    "\n",
    "for i in range(runs):\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i+42)\n",
    "    \n",
    "    outer_cv.get_n_splits(Xall, yall)\n",
    "    for j, (nontest_i, test_i) in enumerate(outer_cv.split(Xall, yall)):\n",
    "        print(f'{j+1}-th Fold.')\n",
    "        X_train, y_train = Xall[nontest_i], yall[nontest_i]\n",
    "        X_test, y_test = Xall[test_i], yall[test_i]\n",
    "        \n",
    "        textmlp = MWrapper(MLP(in_dim, out_dim),\n",
    "                           f'{i}_mlp_gpu{j}')\n",
    "        textmlp.model.apply(weights_init)\n",
    "\n",
    "        dl_train = fd.DataLoader(SimpleBoWDataset(X_train, y_train, in_dim),\n",
    "                                 batch_size=32, num_workers=2,\n",
    "                                 pad_idx=1, transpose=False)\n",
    "        dl_val = fd.DataLoader(SimpleBoWDataset(X_test, y_test, in_dim),\n",
    "                               batch_size=32, num_workers=2,\n",
    "                               pad_idx=1, transpose=False)\n",
    "        modeldata = fs.ModelData(str(textmlp.path), dl_train, dl_val)\n",
    "        learner = fl.Learner.from_model_data(textmlp.model,\n",
    "                                             modeldata,\n",
    "                                             opt_fn=Adam_lambda())\n",
    "        learner.metrics = [f1_micro_skai]\n",
    "        learner.fit(5e-4, 10, best_save_name='best')\n",
    "        \n",
    "        dl_test = fd.DataLoader(SimpleBoWDataset(X_test, y_test, in_dim),\n",
    "                                batch_size=32, num_workers=2,\n",
    "                                pad_idx=1, transpose=False)\n",
    "        learner.load('best')\n",
    "        preds, targs = learner.predict_dl(dl_test)\n",
    "        preds = multilabel_prediction(preds, 0.5)\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_targs.append(targs)\n",
    "        \n",
    "        print(f1_score(np.concatenate(np.array(all_targs), axis=0), \n",
    "                       np.concatenate(np.array(all_preds), axis=0), average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.array(all_preds)\n",
    "all_targs = np.array(all_targs)\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_targs = np.concatenate(all_targs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([all_preds, all_targs], open('data/results/mlp-gpu_10m.pkl', 'wb'))\n",
    "all_preds, all_targs = pickle.load(open('data/results/mlp-gpu_10m.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_preds[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = hamming_loss(all_targs, all_preds)\n",
    "micro_f1 = f1_score(all_targs, all_preds, average='micro')\n",
    "macro_f1 = f1_score(all_targs, all_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss = 0.18793149585228794\n",
      "Micro_F1 = 0.39126289329981806l\n",
      "Macro_F1 = 0.34918186964295644\n"
     ]
    }
   ],
   "source": [
    "print(f'Hamming loss = {hl}\\nMicro_F1 = {micro_f1}l\\nMacro_F1 = {macro_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20-multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: raw data cleaned.\n",
      "multilabel classification.\n"
     ]
    }
   ],
   "source": [
    "trunner = TextRunner([None], top20m[0], top20m[1], 'top20m')\n",
    "in_dim = len(trunner.alldata.tvectorizer.itos)\n",
    "Xall, yall = trunner.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14061\n"
     ]
    }
   ],
   "source": [
    "print(in_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adbae7066df4bda9e6e7922239c01e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai                 \n",
      "    0      0.08945    0.086641   0.106773  \n",
      "    1      0.071075   0.080633   0.238814                      \n",
      "    2      0.054172   0.079652   0.309555                      \n",
      "    3      0.041553   0.082986   0.361689                      \n",
      "    4      0.035716   0.08946    0.377158                      \n",
      "    5      0.029183   0.093995   0.359542                      \n",
      "    6      0.023957   0.087165   0.348648                      \n",
      "    7      0.01986    0.090831   0.35024                       \n",
      "    8      0.014189   0.089929   0.396724                      \n",
      "    9      0.011043   0.090714   0.395725                      \n",
      "\n",
      "0.3972125435540069\n",
      "2-th Fold.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf98d44e8e7249cf9c0d5a68a2f2daba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   f1_micro_skai                 \n",
      "    0      0.090391   0.08207    0.125658  \n",
      "    1      0.071848   0.07677    0.296632                      \n",
      "    2      0.054092   0.077789   0.341522                      \n",
      " 52%|█████▏    | 58/112 [00:00<00:00, 110.29it/s, loss=0.0461]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-51eae863f41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                                              opt_fn=Adam_lambda())\n\u001b[1;32m     29\u001b[0m         \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf1_micro_skai\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_save_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         dl_test = fd.DataLoader(SimpleBoWDataset(X_test, y_test, in_dim),\n",
      "\u001b[0;32m~/Research/Codeforces-clean/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Codeforces-clean/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Codeforces-clean/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Codeforces-clean/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mcopy_fp32_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "out_dim = 20\n",
    "\n",
    "all_preds, all_targs = [], []\n",
    "\n",
    "for i in range(runs):\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i+42)\n",
    "    \n",
    "    outer_cv.get_n_splits(Xall, yall)\n",
    "    for j, (nontest_i, test_i) in enumerate(outer_cv.split(Xall, yall)):\n",
    "        print(f'{j+1}-th Fold.')\n",
    "        X_train, y_train = Xall[nontest_i], yall[nontest_i]\n",
    "        X_test, y_test = Xall[test_i], yall[test_i]\n",
    "        \n",
    "        textmlp = MWrapper(MLP(in_dim, out_dim),\n",
    "                           f'{i}mlp_20_gpu{j}')\n",
    "        textmlp.model.apply(weights_init)\n",
    "\n",
    "        dl_train = fd.DataLoader(SimpleBoWDataset(X_train, y_train, in_dim),\n",
    "                                 batch_size=32, num_workers=2,\n",
    "                                 pad_idx=1, transpose=False)\n",
    "        dl_val = fd.DataLoader(SimpleBoWDataset(X_test, y_test, in_dim),\n",
    "                               batch_size=32, num_workers=2,\n",
    "                               pad_idx=1, transpose=False)\n",
    "        modeldata = fs.ModelData(str(textmlp.path), dl_train, dl_val)\n",
    "        learner = fl.Learner.from_model_data(textmlp.model,\n",
    "                                             modeldata,\n",
    "                                             opt_fn=Adam_lambda())\n",
    "        learner.metrics = [f1_micro_skai]\n",
    "        learner.fit(5e-4, 10, best_save_name='best')\n",
    "        \n",
    "        dl_test = fd.DataLoader(SimpleBoWDataset(X_test, y_test, in_dim),\n",
    "                                batch_size=32, num_workers=2,\n",
    "                                pad_idx=1, transpose=False)\n",
    "        learner.load('best')\n",
    "        preds, targs = learner.predict_dl(dl_test)\n",
    "        preds = multilabel_prediction(preds, 0.5)\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_targs.append(targs)\n",
    "        \n",
    "        print(f1_score(np.concatenate(np.array(all_targs), axis=0), \n",
    "                       np.concatenate(np.array(all_preds), axis=0), average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = np.array(all_preds)\n",
    "all_targs = np.array(all_targs)\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_targs = np.concatenate(all_targs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([all_preds, all_targs], open('data/results/mlp-gpu_20m.pkl', 'wb'))\n",
    "all_preds, all_targs = pickle.load(open('data/results/mlp-gpu_20m.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_preds[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = hamming_loss(all_targs, all_preds)\n",
    "micro_f1 = f1_score(all_targs, all_preds, average='micro')\n",
    "macro_f1 = f1_score(all_targs, all_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss = 0.1167550505050505\n",
      "Micro_F1 = 0.3811818242655424l\n",
      "Macro_F1 = 0.31369342335343253\n"
     ]
    }
   ],
   "source": [
    "print(f'Hamming loss = {hl}\\nMicro_F1 = {micro_f1}l\\nMacro_F1 = {macro_f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
