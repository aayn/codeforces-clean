{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Experiments - Multi-label MNB - CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayn/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = [5, 10]\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, hamming_loss\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from fastai import text as ft\n",
    "from fastai import dataloader as fd\n",
    "from fastai import dataset as fs\n",
    "from fastai import learner as fl\n",
    "from fastai import core as fc\n",
    "from fastai import metrics as fm\n",
    "\n",
    "\n",
    "from skai.runner import TextRunner, Adam_lambda\n",
    "from skai.mwrapper import MWrapper, SKModel\n",
    "from skai.utils import multi_to_text_out, vote_pred\n",
    "from skai.utils import get_classification_type, weights_init, multilabel_prediction\n",
    "from skai.dataset import TokenDataset, SimpleDataset\n",
    "\n",
    "\n",
    "def mapt(f, *iters):\n",
    "    return tuple(map(f, *iters))\n",
    "\n",
    "def mapl(f, *iters):\n",
    "    return list(map(f, *iters))\n",
    "\n",
    "def manually_remove_problems(data):\n",
    "    \"\"\" remove problem from data if it has a certain tag\"\"\"\n",
    "    final_data = {}\n",
    "    remove = ['*special']\n",
    "    for i in data:\n",
    "        if set(data[i][1][0]).intersection(set(remove)) == set():\n",
    "            if data[i][0][0] != '':\n",
    "                final_data[i] = data[i]\n",
    "    return final_data\n",
    "\n",
    "def get_single_label_problems(data):\n",
    "    '''returns a dict of all problems which only have one label'''\n",
    "    single_label_problems = {}\n",
    "    for i in data:\n",
    "        if len(data[i][1][0]) == 1:\n",
    "            single_label_problems[i] = data[i]\n",
    "    return single_label_problems\n",
    "\n",
    "def get_classwise_distribution(data):\n",
    "    class_count = {}\n",
    "    for i in data:\n",
    "        for cls in data[i][1][0]:\n",
    "            if cls in class_count:\n",
    "                class_count[cls] +=1 \n",
    "            else:\n",
    "                class_count[cls] = 1\n",
    "    return class_count\n",
    "\n",
    "\n",
    "def get_topk_single_label_problems(data,k):\n",
    "    \"\"\" get top k by frequency single label problems\"\"\"\n",
    "    class_dict = get_classwise_distribution(data)\n",
    "    print(class_dict)\n",
    "    class_dict = dict(sorted(class_dict.items(), key=itemgetter(1), reverse=True)[:k])\n",
    "    print(set(class_dict.keys()))\n",
    "\n",
    "    topk_data = {}\n",
    "    for i in data:\n",
    "        if set(data[i][1][0]).intersection(set(class_dict.keys())) != set():\n",
    "            topk_data[i] = data[i]\n",
    "            \n",
    "    return topk_data\n",
    "\n",
    "def make_text_dataset(rdata):\n",
    "    Xtext, ytext = [], []\n",
    "    for url, data in rdata.items():\n",
    "        try:\n",
    "            ytext.append(data[1][0][0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        Xtext.append(data[0][0])\n",
    "    return Xtext, ytext\n",
    "\n",
    "def make_multi_text_dataset(rdata):\n",
    "    Xtext, ytext = [], []\n",
    "    for url, data in rdata.items():\n",
    "        try:\n",
    "            ytext.append(data[1][0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        Xtext.append(data[0][0])\n",
    "    return Xtext, ytext\n",
    "\n",
    "def make_statement_dataset(rdata):\n",
    "    Xtext, ytext = [], []\n",
    "    for url, data in rdata.items():\n",
    "        try:\n",
    "            ytext.append(data[1][0][0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        Xtext.append(data[0][2])\n",
    "    return Xtext, ytext\n",
    "\n",
    "def make_non_statement_dataset(rdata):\n",
    "    Xtext, ytext = [], []\n",
    "    for url, data in rdata.items():\n",
    "        try:\n",
    "            ytext.append(data[1][0][0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        Xtext.append(f'{data[0][3]}\\n{data[0][4]}\\n{data[0][5]}')\n",
    "    return Xtext, ytext\n",
    "\n",
    "def get_class_list(labels):\n",
    "    return list(set(labels))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(22, 16)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0.0, vmax=1.0)\n",
    "#     plt.title(title, fontsize)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=32)\n",
    "    plt.yticks(tick_marks, classes, fontsize=32)\n",
    "\n",
    "    print(cm.max())\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = 0.5\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=32)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=32)\n",
    "    plt.xlabel('Predicted label', fontsize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10m = pickle.load(open('data/10multi_26aug.pkl','rb'))\n",
    "top20m = pickle.load(open('data/20multi_26aug.pkl','rb'))\n",
    "\n",
    "top10m, top20m = mapt(make_multi_text_dataset, [top10m, top20m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary search', 'data structures', 'brute force', 'dp']\n"
     ]
    }
   ],
   "source": [
    "print(top10m[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNB Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Model directory for mnb exists.\n"
     ]
    }
   ],
   "source": [
    "mnb = SKModel(Pipeline(\n",
    "    [('countvec', CountVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB()))]),\n",
    "    {'countvec__max_df': (0.25, 0.5, 0.75),\n",
    "     'countvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "     'clf__estimator__alpha': [0.25, 0.5, 0.75, 1]}) \n",
    "mnb = MWrapper(mnb, 'mnb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-class experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: raw data cleaned.\n",
      "multilabel classification.\n"
     ]
    }
   ],
   "source": [
    "trunner = TextRunner([mnb], top10m[0], top10m[1], 'top10m', make_pyt_data=False)\n",
    "Xall, yall = np.array(trunner.rdata), np.array(trunner.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11764705882352941\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12032085561497326\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12566844919786097\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12366310160427807\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11978609625668449\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12076648841354724\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12337662337662338\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12571046472751587\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12990487514863258\n",
      "{'math', 'implementation', 'constructive algorithms', 'dp', 'data structures', 'greedy', 'dfs and similar', 'binary search', 'sortings', 'brute force'}\n",
      "10\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13005084292213004\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "out_dim = 10\n",
    "\n",
    "preds_txt, targs_txt = [], []\n",
    "\n",
    "for i in range(runs):\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i+42)\n",
    "    \n",
    "    outer_cv.get_n_splits(Xall, yall)\n",
    "    for j, (nontest_i, test_i) in enumerate(outer_cv.split(Xall, yall)):\n",
    "        X_train, y_train = Xall[nontest_i], yall[nontest_i]\n",
    "        X_test, y_test = Xall[test_i], yall[test_i]\n",
    "        \n",
    "        clf, score = trunner.get_clf_sk(mnb, X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        y_test = trunner.alldata.ovectorizer.transform(y_test)\n",
    "        \n",
    "        preds_txt.append(preds)\n",
    "        targs_txt.append(y_test)\n",
    "        print(accuracy_score(np.concatenate(targs_txt),\n",
    "                             np.concatenate(preds_txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_txt = np.concatenate(preds_txt)\n",
    "targs_txt = np.concatenate(targs_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(targs_txt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([preds_txt, targs_txt], open('data/results/mnb_10m.pkl', 'wb'))\n",
    "preds_txt, targs_txt = pickle.load(open('data/results/mnb_10m.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss = 0.1706181428953706\n",
      "Micro_F1 = 0.3057491289198606l\n",
      "Macro_F1 = 0.25736132541303536\n"
     ]
    }
   ],
   "source": [
    "hl = hamming_loss(targs_txt, preds_txt)\n",
    "micro_f1 = f1_score(targs_txt, preds_txt, average='micro')\n",
    "macro_f1 = f1_score(targs_txt, preds_txt, average='macro')\n",
    "\n",
    "print(f'Hamming loss = {hl}\\nMicro_F1 = {micro_f1}l\\nMacro_F1 = {macro_f1}')\n",
    "# plot_confusion_matrix(trunner.y_test, predictions_sv,\n",
    "#                       get_class_list(trunner.y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20-class experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint reached: raw data cleaned.\n",
      "multilabel classification.\n"
     ]
    }
   ],
   "source": [
    "trunner = TextRunner([mnb], top20m[0], top20m[1], 'top20m', make_pyt_data=False)\n",
    "Xall, yall = np.array(trunner.rdata), np.array(trunner.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08838383838383838\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07702020202020202\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07912457912457913\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07828282828282829\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08181818181818182\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'sortings', 'brute force', 'bitmasks', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08038720538720538\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08008658008658008\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07954545454545454\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07856341189674523\n",
      "{'math', 'strings', 'implementation', 'graphs', 'constructive algorithms', 'geometry', 'dp', 'dsu', 'data structures', 'trees', 'greedy', 'dfs and similar', 'two pointers', 'binary search', 'bitmasks', 'brute force', 'sortings', 'number theory', 'probabilities', 'combinatorics'}\n",
      "20\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=5)]: Done 108 out of 108 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07929292929292929\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "out_dim = 20\n",
    "\n",
    "preds_txt, targs_txt = [], []\n",
    "\n",
    "for i in range(runs):\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i+42)\n",
    "    \n",
    "    outer_cv.get_n_splits(Xall, yall)\n",
    "    for j, (nontest_i, test_i) in enumerate(outer_cv.split(Xall, yall)):\n",
    "        X_train, y_train = Xall[nontest_i], yall[nontest_i]\n",
    "        X_test, y_test = Xall[test_i], yall[test_i]\n",
    "        \n",
    "        clf, score = trunner.get_clf_sk(mnb, X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        y_test = trunner.alldata.ovectorizer.transform(y_test)\n",
    "        \n",
    "        preds_txt.append(preds)\n",
    "        targs_txt.append(y_test)\n",
    "        print(accuracy_score(np.concatenate(targs_txt),\n",
    "                             np.concatenate(preds_txt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_txt = np.concatenate(preds_txt)\n",
    "targs_txt = np.concatenate(targs_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(targs_txt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([preds_txt, targs_txt], open('data/results/mnb_20m.pkl', 'wb'))\n",
    "preds_txt, targs_txt = pickle.load(open('data/results/mnb_20m.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss = 0.10669191919191919\n",
      "Micro_F1 = 0.2966539037789246l\n",
      "Macro_F1 = 0.23411972853832436\n"
     ]
    }
   ],
   "source": [
    "hl = hamming_loss(targs_txt, preds_txt)\n",
    "micro_f1 = f1_score(targs_txt, preds_txt, average='micro')\n",
    "macro_f1 = f1_score(targs_txt, preds_txt, average='macro')\n",
    "\n",
    "print(f'Hamming loss = {hl}\\nMicro_F1 = {micro_f1}l\\nMacro_F1 = {macro_f1}')\n",
    "# plot_confusion_matrix(trunner.y_test, predictions_sv,\n",
    "#                       get_class_list(trunner.y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
